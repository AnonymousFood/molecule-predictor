{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.utils import from_networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Generation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_connected_subgraph(G, size=4):\n",
    "    \"\"\"Find a connected subgraph of specified size\"\"\"\n",
    "    for component in nx.connected_components(G):\n",
    "        subgraph = G.subgraph(component)\n",
    "        if len(subgraph) >= size:\n",
    "            start_node = np.random.choice(list(subgraph.nodes()))\n",
    "            nodes = list(nx.bfs_tree(subgraph, start_node))[:size]\n",
    "            return nodes\n",
    "    return None\n",
    "\n",
    "def generate_graph(num_nodes=100, edge_prob=0.05):\n",
    "    \"\"\"Generate a random graph ensuring it has at least one connected component of size 4\"\"\"\n",
    "    while True:\n",
    "        G = nx.erdos_renyi_graph(n=num_nodes, p=edge_prob)\n",
    "        connected_nodes = find_connected_subgraph(G, size=4)\n",
    "        if connected_nodes is not None:\n",
    "            return G, connected_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Computation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(G, nodes):\n",
    "    \"\"\"Compute graph features including specific node features\"\"\"\n",
    "    if nodes is None or len(nodes) != 4:\n",
    "        raise ValueError(\"Must provide exactly 4 nodes for feature computation\")\n",
    "    \n",
    "    num_nodes = G.number_of_nodes()\n",
    "    if num_nodes == 0:\n",
    "        return torch.zeros(10, dtype=torch.float32)\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    # Node-specific features for the provided nodes\n",
    "    for node in nodes:\n",
    "        # Basic metrics\n",
    "        degree = G.degree[node]\n",
    "        clustering = nx.clustering(G, node)\n",
    "        avg_neighbor_degree = np.mean([G.degree[n] \n",
    "                               for n in G.neighbors(node)]) if list(G.neighbors(node)) else 0\n",
    "            \n",
    "        # Centrality metrics\n",
    "        betweenness = nx.betweenness_centrality(G)[node]\n",
    "        closeness = nx.closeness_centrality(G)[node]\n",
    "        pagerank = nx.pagerank(G)[node]\n",
    "            \n",
    "        # Handle eigenvector centrality\n",
    "        try:\n",
    "            eigenvector = nx.eigenvector_centrality_numpy(G)[node]\n",
    "        except (nx.NetworkXError, nx.AmbiguousSolution):\n",
    "            eigenvector = 0\n",
    "            \n",
    "        # Structural metrics\n",
    "        core_number = nx.core_number(G)[node]\n",
    "        local_efficiency = nx.local_efficiency(G)\n",
    "            \n",
    "        node_features = [\n",
    "            degree,\n",
    "            clustering,\n",
    "            avg_neighbor_degree,\n",
    "            betweenness,\n",
    "            closeness,\n",
    "            pagerank,\n",
    "            eigenvector,\n",
    "            core_number,\n",
    "            local_efficiency\n",
    "        ]\n",
    "        features.extend(node_features)\n",
    "    \n",
    "    # Global node-level features (averaged)\n",
    "    degrees = [d for _, d in G.degree()]\n",
    "    clustering_coeffs = [nx.clustering(G, node) for node in G.nodes()]\n",
    "    neighbor_degrees = [np.mean([G.degree[n] for n in G.neighbors(node)]) if list(G.neighbors(node)) else 0 \n",
    "                       for node in G.nodes()]\n",
    "    betweenness = list(nx.betweenness_centrality(G).values())\n",
    "    closeness = list(nx.closeness_centrality(G).values())\n",
    "    pagerank = list(nx.pagerank(G).values())\n",
    "    \n",
    "    # Handle eigenvector centrality for all nodes\n",
    "    try:\n",
    "        eigenvector = list(nx.eigenvector_centrality_numpy(G).values())\n",
    "    except (nx.NetworkXError, nx.AmbiguousSolution):\n",
    "        eigenvector = [0] * num_nodes\n",
    "    \n",
    "    core_numbers = list(nx.core_number(G).values())\n",
    "    \n",
    "    # Calculate global averages\n",
    "    avg_features = [\n",
    "        np.mean(degrees),\n",
    "        np.mean(clustering_coeffs),\n",
    "        np.mean(neighbor_degrees),\n",
    "        np.mean(betweenness),\n",
    "        np.mean(closeness),\n",
    "        np.mean(pagerank),\n",
    "        np.mean(eigenvector),\n",
    "        np.mean(core_numbers),\n",
    "        nx.local_efficiency(G)\n",
    "    ]\n",
    "    \n",
    "    # Global features\n",
    "    global_features = [\n",
    "        nx.density(G)\n",
    "    ]\n",
    "    \n",
    "    # Combine all features\n",
    "    features.extend(avg_features + global_features)\n",
    "    return torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "def prepare_node_features(G):\n",
    "    \"\"\"Prepare node features including removal flag\"\"\"\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    # Basic features for each node (5 base features + 1 removal flag)\n",
    "    features = torch.zeros(num_nodes, 6)\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        features[i] = torch.tensor([\n",
    "            G.degree[i],\n",
    "            nx.clustering(G, i),\n",
    "            np.mean([G.degree[n] for n in G.neighbors(i)]) if list(G.neighbors(i)) else 0,\n",
    "            list(nx.betweenness_centrality(G).values())[i],\n",
    "            list(nx.closeness_centrality(G).values())[i],\n",
    "            0  # Removal flag, will be set later\n",
    "        ])\n",
    "    return features\n",
    "\n",
    "def prepare_edge_index(G):\n",
    "    \"\"\"Convert NetworkX graph edges to PyG edge index\"\"\"\n",
    "    return torch.tensor([[e[0], e[1]] for e in G.edges()]).t().contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_graph_data(G, nodes_to_remove):\n",
    "    \"\"\"Process a graph to create training data\"\"\"\n",
    "    # Original graph features\n",
    "    original_features = compute_features(G, nodes_to_remove)\n",
    "    \n",
    "    # Create residual graph\n",
    "    residual_G = G.copy()\n",
    "    residual_G.remove_nodes_from(nodes_to_remove)\n",
    "    \n",
    "    # Get features for residual graph\n",
    "    largest_component = max(nx.connected_components(residual_G), key=len)\n",
    "    residual_G_main = residual_G.subgraph(largest_component)\n",
    "    residual_features = compute_features(residual_G_main, \n",
    "                                       list(residual_G_main.nodes())[:4] if len(residual_G_main) >= 4 else None)\n",
    "    \n",
    "    # Create PyG data object\n",
    "    data = Data(\n",
    "        x=prepare_node_features(G),\n",
    "        edge_index=prepare_edge_index(G),\n",
    "        removed_nodes=torch.tensor(nodes_to_remove),\n",
    "        original_features=original_features,\n",
    "        residual_features=residual_features\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedGNNModel(nn.Module):\n",
    "    def __init__(self, node_feature_dim, hidden_dim):\n",
    "        super(EnhancedGNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(node_feature_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Separate MLPs for different feature types\n",
    "        self.node_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 9)  # 9 features per node\n",
    "        )\n",
    "        \n",
    "        self.global_mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 10)  # Global graph features\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        batch = data.batch if hasattr(data, 'batch') else torch.zeros(x.size(0), dtype=torch.long)\n",
    "        \n",
    "        # Graph convolutions\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        \n",
    "        # Process removed nodes\n",
    "        removed_features = []\n",
    "        for node in data.removed_nodes:\n",
    "            node_feat = self.node_mlp(x[node])\n",
    "            removed_features.append(node_feat)\n",
    "        removed_features = torch.stack(removed_features)  # Shape: [4, 9]\n",
    "        removed_features = removed_features.view(1, -1)  # Reshape to [1, 36]\n",
    "        \n",
    "        # Global graph features\n",
    "        global_x = global_mean_pool(x, batch)  # Shape: [1, hidden_dim]\n",
    "        global_features = self.global_mlp(global_x)  # Shape: [1, 10]\n",
    "        \n",
    "        return torch.cat([removed_features, global_features], dim=1)  # Shape: [1, 46]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 4 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize and train model\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m EnhancedGNNModel(node_feature_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, data, target, epochs, lr)\u001b[0m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, target)\n\u001b[0;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Will\\miniforge3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Will\\miniforge3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[28], line 46\u001b[0m, in \u001b[0;36mEnhancedGNNModel.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     43\u001b[0m global_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_mlp(global_x)  \u001b[38;5;66;03m# Shape: [1, 10]\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Repeat global features to match removed_features batch size\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mremoved_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 4 but got size 1 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Generate graph and prepare data\n",
    "G, selected_nodes = generate_graph(num_nodes=100, edge_prob=0.05)\n",
    "data = process_graph_data(G, selected_nodes)\n",
    "\n",
    "# Set removal flags for selected nodes\n",
    "data.x[selected_nodes, -1] = 1\n",
    "\n",
    "# Initialize and train model\n",
    "model = EnhancedGNNModel(node_feature_dim=6, hidden_dim=64)\n",
    "train_model(model, data, data.original_features.unsqueeze(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
